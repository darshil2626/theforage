{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e13dd0ff",
   "metadata": {},
   "source": [
    "Here is your task\n",
    "\n",
    "The risk manager has collected data on the loan borrowers. The data is in tabular format, with each row providing details of the borrower, including their income, total loans outstanding, and a few other metrics. There is also a column indicating if the borrower has previously defaulted on a loan. You must use this data to build a model that, given details for any loan described above, will predict the probability that the borrower will default (also known as PD: the probability of default). Use the provided data to train a function that will estimate the probability of default for a borrower. Assuming a recovery rate of 10%, this can be used to give the expected loss on a loan.\n",
    "\n",
    "You should produce a function that can take in the properties of a loan and output the expected loss.\n",
    "You can explore any technique ranging from a simple regression or a decision tree to something more advanced. You can also use multiple methods and provide a comparative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c525c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\darsh\\Documents\\theforage\\JPMorgan Quantitative Research\\Task_3_and_4_Loan_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb01e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - AUC: 1.000, Accuracy: 0.996\n",
      "Random Forest - AUC: 1.000, Accuracy: 0.996\n",
      "Gradient Boosting - AUC: 1.000, Accuracy: 0.996\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Load your dataset\n",
    "# df = pd.read_csv(\"loan_data.csv\")  # uncomment and modify if you have the CSV\n",
    "# For this mock-up, we assume df is already available\n",
    "\n",
    "# Assume 'defaulted' is the target column\n",
    "TARGET = 'default'\n",
    "RECOVERY_RATE = 0.1  # 10% recovery\n",
    "\n",
    "# Step 1: Preprocessing\n",
    "def preprocess_and_split(df):\n",
    "    X = df.drop(columns=[TARGET])\n",
    "    y = df[TARGET]\n",
    "\n",
    "    # Separate numerical and categorical features\n",
    "    num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    cat_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Preprocessing pipelines\n",
    "    num_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', num_pipeline, num_features),\n",
    "        ('cat', cat_pipeline, cat_features)\n",
    "    ])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, preprocessor\n",
    "\n",
    "# Step 2: Train Models\n",
    "def train_models(X_train, y_train, preprocessor):\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    }\n",
    "\n",
    "    fitted_models = {}\n",
    "    for name, model in models.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        fitted_models[name] = pipeline\n",
    "\n",
    "    return fitted_models\n",
    "\n",
    "# Step 3: Evaluate Models\n",
    "def evaluate_models(models, X_test, y_test):\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"{name} - AUC: {auc:.3f}, Accuracy: {acc:.3f}\")\n",
    "\n",
    "# Step 4: Define Prediction Function for Expected Loss\n",
    "def make_expected_loss_function(model):\n",
    "    def expected_loss(input_dict):\n",
    "        input_df = pd.DataFrame([input_dict])\n",
    "        pd_prob = model.predict_proba(input_df)[0][1]\n",
    "        expected_loss = pd_prob * (1 - RECOVERY_RATE)\n",
    "        return {\n",
    "            'Probability of Default': pd_prob,\n",
    "            'Expected Loss': expected_loss\n",
    "        }\n",
    "    return expected_loss\n",
    "\n",
    "# Sample usage\n",
    "X_train, X_test, y_train, y_test, preprocessor = preprocess_and_split(df)\n",
    "models = train_models(X_train, y_train, preprocessor)\n",
    "evaluate_models(models, X_test, y_test)\n",
    "\n",
    "# Choose best model\n",
    "best_model = models['Gradient Boosting']  # for example\n",
    "expected_loss_fn = make_expected_loss_function(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d337f133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
